{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "from sshtunnel import SSHTunnelForwarder\n",
    "import psycopg2\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# SSH connection details.\n",
    "ssh_host = 'loki.research.cs.dal.ca'\n",
    "ssh_port = 22\n",
    "ssh_username = os.getenv('LOKI_USERNAME')\n",
    "ssh_password = os.getenv('LOKI_PASSWORD')\n",
    "\n",
    "# Database connection details.\n",
    "db_host = '127.0.0.1'\n",
    "db_port = 5432\n",
    "db_name = 'staging_db'\n",
    "db_user = os.getenv('STAGING_DB_USERNAME')\n",
    "db_password = os.getenv('STAGING_DB_PASSWORD')\n",
    "\n",
    "# Establish SSH tunnel and connect to PostgreSQL.\n",
    "try:\n",
    "    with SSHTunnelForwarder(\n",
    "        (ssh_host, ssh_port),\n",
    "        ssh_username=ssh_username,\n",
    "        ssh_password=ssh_password,\n",
    "        remote_bind_address=('127.0.0.1', db_port)  # Forwarding PostgreSQL port.\n",
    "    ) as tunnel:\n",
    "    \n",
    "        # Connect to PostgreSQL database through the SSH tunnel.\n",
    "        conn = psycopg2.connect(\n",
    "            host=db_host,\n",
    "            port=tunnel.local_bind_port,  # use the local port set by the tunnel.\n",
    "            dbname=db_name,\n",
    "            user=db_user,\n",
    "            password=db_password\n",
    "        )\n",
    "        \n",
    "        print(\"Database connection established\")\n",
    "        lock_state_query = \"SELECT * FROM study_prositvd.lock_state;\"\n",
    "        accelerometer_query = \"SELECT * FROM study_prositvd.accelerometer;\"\n",
    "        df_lock_state = pd.read_sql_query(lock_state_query, conn)\n",
    "        df_accelerometer = pd.read_sql_query(accelerometer_query, conn)\n",
    "        \n",
    "        # Close database connection.\n",
    "        conn.close()\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Raw data.\n",
    "df_lock_state.head(10)"
   ],
   "id": "12d4677f60d88aee",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "df_accelerometer.head(10)",
   "id": "99003dde0784cc5f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Screen time from Lock state data.",
   "id": "352ae3bfe8ade5f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "df_lock_state['measuredat'] = pd.to_datetime(df_lock_state['measuredat'])\n",
    "\n",
    "# Define the logical time window.\n",
    "window_start_time = pd.to_datetime('22:00:00').time()  # 10 PM\n",
    "window_end_time = pd.to_datetime('07:00:00').time()    # 7 AM\n",
    "\n",
    "# Function to assign logical day based on the window (because window can span over two calendar days).\n",
    "def assign_logical_day(row):\n",
    "    measured_time = row['measuredat'].time()\n",
    "    \n",
    "    if measured_time >= window_start_time:\n",
    "        return row['measuredat'].date()  # Assign to the current day.\n",
    "    else:\n",
    "        return (row['measuredat'] - pd.Timedelta(days=1)).date()  # Assign to the previous day.\n",
    "\n",
    "# Assign logical day to the DataFrame.\n",
    "df_lock_state['logical_day'] = df_lock_state.apply(assign_logical_day, axis=1)\n",
    "\n",
    "# Function to calculate screen times and metrics within logical windows.\n",
    "def calculate_metrics(group):\n",
    "    locked_time = pd.Timedelta(0)\n",
    "    unlocked_time = pd.Timedelta(0)\n",
    "    unlock_durations = []\n",
    "    total_unlocks = 0\n",
    "\n",
    "    previous_state = None\n",
    "    previous_time = None\n",
    "    \n",
    "    # Set the logical start and end time boundaries based on the logical day.\n",
    "    logical_start = pd.Timestamp.combine(group['logical_day'].iloc[0], window_start_time)\n",
    "    logical_end = pd.Timestamp.combine(group['logical_day'].iloc[0] + pd.Timedelta(days=1), window_end_time)\n",
    "\n",
    "    for _, row in group.iterrows():\n",
    "        current_state = row['value0']\n",
    "        current_time = row['measuredat']\n",
    "        \n",
    "        # Adjust previous time if crossing into the time window.\n",
    "        if previous_time and previous_time < logical_start < current_time:\n",
    "            previous_time = logical_start\n",
    "        \n",
    "        # Adjust current time if crossing the window end.\n",
    "        if current_time > logical_end:\n",
    "            current_time = logical_end\n",
    "\n",
    "        # Valid transition: LOCKED -> UNLOCKED\n",
    "        if previous_state == 'LOCKED' and current_state == 'UNLOCKED':\n",
    "            if previous_time >= logical_start and current_time <= logical_end:\n",
    "                locked_time += current_time - previous_time\n",
    "        \n",
    "        # Valid transition: UNLOCKED -> LOCKED\n",
    "        elif previous_state == 'UNLOCKED' and current_state == 'LOCKED':\n",
    "            if previous_time >= logical_start and current_time <= logical_end:\n",
    "                duration = current_time - previous_time\n",
    "                unlocked_time += duration\n",
    "                unlock_durations.append(duration.total_seconds() / 60)  # Convert to minutes.\n",
    "                total_unlocks += 1\n",
    "\n",
    "        # Update the previous state and time.\n",
    "        previous_state = current_state\n",
    "        previous_time = current_time\n",
    "\n",
    "    # Calculate statistics.\n",
    "    mean_unlock = np.mean(unlock_durations) if unlock_durations else 0\n",
    "    median_unlock = np.median(unlock_durations) if unlock_durations else 0\n",
    "    max_unlock = max(unlock_durations) if unlock_durations else 0\n",
    "\n",
    "    return pd.Series({\n",
    "        'total_screen_locked_time': locked_time.total_seconds() / 60,\n",
    "        'total_screen_unlocked_time': unlocked_time.total_seconds() / 60,\n",
    "        'total_number_of_unlocks': total_unlocks,\n",
    "        'mean_unlocked_duration': mean_unlock,\n",
    "        'median_unlocked_duration': median_unlock,\n",
    "        'max_unlocked_duration': max_unlock\n",
    "    })\n",
    "\n",
    "# Group by participant id and logical day, and apply the metric calculations.\n",
    "result_df_lock_state = (\n",
    "    df_lock_state.groupby(['participantid', 'logical_day'])\n",
    "    .apply(calculate_metrics)\n",
    "    .reset_index()\n",
    ")"
   ],
   "id": "aac4bcde7a3541ae",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "result_df_lock_state.head(10)",
   "id": "4a4425216876c61d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Screen time from Accelerometer data",
   "id": "97b890427488ac7e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "df_accelerometer['measuredat'] = pd.to_datetime(df_accelerometer['measuredat'])\n",
    "\n",
    "# Convert the accelerometer values to numeric (float)\n",
    "df_accelerometer['value0'] = pd.to_numeric(df_accelerometer['value0'], errors='coerce')\n",
    "df_accelerometer['value1'] = pd.to_numeric(df_accelerometer['value1'], errors='coerce')\n",
    "df_accelerometer['value2'] = pd.to_numeric(df_accelerometer['value2'], errors='coerce')\n",
    "\n",
    "# Calculate movement magnitude (RMS) from accelerometer values\n",
    "df_accelerometer['movement_magnitude'] = np.sqrt(df_accelerometer['value0']**2 + df_accelerometer['value1']**2 + df_accelerometer['value2']**2)"
   ],
   "id": "d00e43d54ea3c30d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Define the logical time window\n",
    "window_start_time = pd.to_datetime('22:00:00').time()  # 10 PM\n",
    "window_end_time = pd.to_datetime('07:00:00').time()    # 7 AM"
   ],
   "id": "5ed9ea1ddda26e5",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Assign logical day based on the time window.\n",
    "def assign_logical_day(row):\n",
    "    measured_time = row['measuredat'].time()\n",
    "    \n",
    "    if measured_time >= window_start_time:\n",
    "        return row['measuredat'].date()  # Assign to the current day\n",
    "    else:\n",
    "        return (row['measuredat'] - pd.Timedelta(days=1)).date()  # Assign to the previous day\n",
    "\n",
    "df_accelerometer['logical_day'] = df_accelerometer.apply(assign_logical_day, axis=1)"
   ],
   "id": "bb5300226a80fcb7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Calculate the median movement magnitude for each participant and logical day.\n",
    "df_accelerometer['daily_median'] = df_accelerometer.groupby(['participantid', 'logical_day'])['movement_magnitude'].transform('median')"
   ],
   "id": "96df1228888a98ea",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Create the 'is_asleep' column based on whether movement_magnitude is below the daily median\n",
    "df_accelerometer['is_asleep'] = df_accelerometer['movement_magnitude'] < df_accelerometer['daily_median']"
   ],
   "id": "1a03191ded386407",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Function to calculate sleep times and other metrics, similar to how we handled the lock_state data.\n",
    "def calculate_sleep_metrics(group):\n",
    "    sleep_time = pd.Timedelta(0)\n",
    "    wake_time = pd.Timedelta(0)\n",
    "    sleep_durations = []\n",
    "    total_sleep_segments = 0\n",
    "\n",
    "    previous_state = None\n",
    "    previous_time = None\n",
    "    \n",
    "    # Set the logical start and end time boundaries based on the logical day\n",
    "    logical_start = pd.Timestamp.combine(group['logical_day'].iloc[0], window_start_time)\n",
    "    logical_end = pd.Timestamp.combine(group['logical_day'].iloc[0] + pd.Timedelta(days=1), window_end_time)\n",
    "\n",
    "    for _, row in group.iterrows():\n",
    "        current_state = row['is_asleep']\n",
    "        current_time = row['measuredat']\n",
    "        \n",
    "        # Adjust previous time if crossing into the time window.\n",
    "        if previous_time and previous_time < logical_start < current_time:\n",
    "            previous_time = logical_start\n",
    "        \n",
    "        # Adjust current time if crossing the window end.\n",
    "        if current_time > logical_end:\n",
    "            current_time = logical_end\n",
    "\n",
    "        # Transition: Awake -> Asleep\n",
    "        if previous_state == False and current_state == True:\n",
    "            if previous_time >= logical_start and current_time <= logical_end:\n",
    "                wake_time += current_time - previous_time\n",
    "        \n",
    "        # Transition: Asleep -> Awake\n",
    "        elif previous_state == True and current_state == False:\n",
    "            if previous_time >= logical_start and current_time <= logical_end:\n",
    "                duration = current_time - previous_time\n",
    "                sleep_time += duration\n",
    "                sleep_durations.append(duration.total_seconds() / 60)  # Convert to minutes.\n",
    "                total_sleep_segments += 1\n",
    "\n",
    "        # Update the previous state and time.\n",
    "        previous_state = current_state\n",
    "        previous_time = current_time\n",
    "\n",
    "    # Calculate statistics.\n",
    "    mean_sleep_duration = np.mean(sleep_durations) if sleep_durations else 0\n",
    "    median_sleep_duration = np.median(sleep_durations) if sleep_durations else 0\n",
    "    max_sleep_duration = max(sleep_durations) if sleep_durations else 0\n",
    "\n",
    "    return pd.Series({\n",
    "        'total_sleep_time': sleep_time.total_seconds() / 60,\n",
    "        'total_wake_time': wake_time.total_seconds() / 60,\n",
    "        'total_sleep_segments': total_sleep_segments,\n",
    "        'mean_sleep_duration': mean_sleep_duration,\n",
    "        'median_sleep_duration': median_sleep_duration,\n",
    "        'max_sleep_duration': max_sleep_duration\n",
    "    })\n",
    "\n",
    "# Group by participant id and logical day, and apply the metric calculations.\n",
    "result_df_accel = (\n",
    "    df_accelerometer.groupby(['participantid', 'logical_day'])\n",
    "    .apply(calculate_sleep_metrics)\n",
    "    .reset_index()\n",
    ")"
   ],
   "id": "d06157571175078d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "result_df_accel.head(10)",
   "id": "1ddbb454fc591500",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "result_df_lock_state.head(10)",
   "id": "60d907f267e9433c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "c59c39873ada351c",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
